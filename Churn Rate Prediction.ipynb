{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working directory\n",
    "os.chdir(\"C:\\\\Users\\\\shive\\\\Desktop\\\\MS-BAIM\\\\Courses\\\\online courses\\\\A-Z Deep Learning\\\\Deep_Learning_A_Z\\\\Volume 1 - Supervised Deep Learning\\\\Part 1 - Artificial Neural Networks (ANN)\\\\Section 4 - Building an ANN\\\\Artificial_Neural_Networks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset= pd.read_csv(\"Churn_Modelling.csv\")\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variables\n",
    "geography= pd.get_dummies(dataset[\"Geography\"], drop_first= True)\n",
    "#geography.head(5)\n",
    "gender= pd.get_dummies(dataset[\"Gender\"], drop_first= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Male  Germany  Spain  CreditScore  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0     0        0      0          619   42       2       0.00              1   \n",
       "1     0        0      1          608   41       1   83807.86              1   \n",
       "2     0        0      0          502   42       8  159660.80              3   \n",
       "3     0        0      0          699   39       1       0.00              2   \n",
       "4     0        0      1          850   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping irrelevant columns and concatinating created dummy variables\n",
    "dataset= dataset.drop([\"Geography\", \"Gender\", \"RowNumber\", \"CustomerId\", \"Surname\"], axis=1)\n",
    "dataset= pd.concat([geography, dataset], axis=1)\n",
    "dataset= pd.concat([gender, dataset], axis=1)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering parameters which might affect churn rate based on business intuition\n",
    "x= dataset.iloc[:, :11].values\n",
    "y= dataset.iloc[:, 11].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.1900000e+02,\n",
       "        4.2000000e+01, 2.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 1.0134888e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.0800000e+02,\n",
       "        4.1000000e+01, 1.0000000e+00, 8.3807860e+04, 1.0000000e+00,\n",
       "        0.0000000e+00, 1.0000000e+00, 1.1254258e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 5.0200000e+02,\n",
       "        4.2000000e+01, 8.0000000e+00, 1.5966080e+05, 3.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 1.1393157e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.9900000e+02,\n",
       "        3.9000000e+01, 1.0000000e+00, 0.0000000e+00, 2.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 9.3826630e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.5000000e+02,\n",
       "        4.3000000e+01, 2.0000000e+00, 1.2551082e+05, 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 7.9084100e+04]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into training ans test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split (x,y, test_size=0.2, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.6700000e+02,\n",
       "        3.4000000e+01, 5.0000000e+00, 0.0000000e+00, 2.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 1.6383064e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 4.2700000e+02,\n",
       "        4.2000000e+01, 1.0000000e+00, 7.5681520e+04, 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 5.7098000e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 5.3500000e+02,\n",
       "        2.9000000e+01, 2.0000000e+00, 1.1236734e+05, 1.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 1.8563076e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.5400000e+02,\n",
       "        4.0000000e+01, 5.0000000e+00, 1.0568363e+05, 1.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 1.7361709e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.5000000e+02,\n",
       "        5.7000000e+01, 8.0000000e+00, 1.2677630e+05, 2.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 1.3229849e+05]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "x_train= sc.fit_transform(x_train)\n",
    "x_test= sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.09168714, -0.5698444 ,  1.74309049,  0.16958176, -0.46460796,\n",
       "          0.00666099, -1.21571749,  0.8095029 ,  0.64259497, -1.03227043,\n",
       "          1.10643166],\n",
       "        [ 0.91601335,  1.75486502, -0.57369368, -2.30455945,  0.30102557,\n",
       "         -1.37744033, -0.00631193, -0.92159124,  0.64259497,  0.9687384 ,\n",
       "         -0.74866447],\n",
       "        [-1.09168714, -0.5698444 , -0.57369368, -1.19119591, -0.94312892,\n",
       "         -1.031415  ,  0.57993469, -0.92159124,  0.64259497, -1.03227043,\n",
       "          1.48533467],\n",
       "        [ 0.91601335, -0.5698444 ,  1.74309049,  0.03556578,  0.10961719,\n",
       "          0.00666099,  0.47312769, -0.92159124,  0.64259497, -1.03227043,\n",
       "          1.27652776],\n",
       "        [-1.09168714, -0.5698444 ,  1.74309049,  2.05611444,  1.73658844,\n",
       "          1.04473698,  0.8101927 ,  0.8095029 ,  0.64259497,  0.9687384 ,\n",
       "          0.55837842]]),\n",
       " array([[-1.09168714,  1.75486502, -0.57369368, -0.55204276, -0.36890377,\n",
       "          1.04473698,  0.8793029 , -0.92159124,  0.64259497,  0.9687384 ,\n",
       "          1.61085707],\n",
       "        [-1.09168714, -0.5698444 , -0.57369368, -1.31490297,  0.10961719,\n",
       "         -1.031415  ,  0.42972196, -0.92159124,  0.64259497, -1.03227043,\n",
       "          0.49587037],\n",
       "        [-1.09168714, -0.5698444 ,  1.74309049,  0.57162971,  0.30102557,\n",
       "          1.04473698,  0.30858264, -0.92159124,  0.64259497,  0.9687384 ,\n",
       "         -0.42478674],\n",
       "        [ 0.91601335, -0.5698444 , -0.57369368,  1.41696129, -0.65601634,\n",
       "         -0.33936434,  0.57533623, -0.92159124, -1.55619021, -1.03227043,\n",
       "         -0.18777657],\n",
       "        [ 0.91601335,  1.75486502, -0.57369368,  0.57162971, -0.08179119,\n",
       "          0.00666099,  1.38961097,  0.8095029 ,  0.64259497,  0.9687384 ,\n",
       "          0.61684179]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5], x_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the ANN\n",
    "ann_classifier= Sequential()\n",
    "#adding input layers and hidden layers\n",
    "ann_classifier.add(Dense(6, activation= \"relu\", kernel_initializer= \"uniform\", input_shape= (11,)))\n",
    "ann_classifier.add(Dropout(p= 0.1))\n",
    "#adding second hidden layers\n",
    "ann_classifier.add(Dense(6, activation= \"relu\", kernel_initializer= \"uniform\"))\n",
    "ann_classifier.add(Dropout(p= 0.1))\n",
    "#adding the output layer\n",
    "ann_classifier.add(Dense(1, activation= \"sigmoid\", kernel_initializer= \"uniform\"))\n",
    "#compiling the ANN\n",
    "ann_classifier.compile(optimizer=\"adam\", loss= \"binary_crossentropy\", metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.4803 - accuracy: 0.7960\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4273 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 0.4220 - accuracy: 0.8006\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 0.4182 - accuracy: 0.8244 0s - loss: 0.4187 - accu\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4163 - accuracy: 0.8284\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.4141 - accuracy: 0.8316 0s - loss: 0.4134 - accuracy: 0.\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.4132 - accuracy: 0.8316\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.4117 - accuracy: 0.8350\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.4105 - accuracy: 0.8346\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4100 - accuracy: 0.8325\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4089 - accuracy: 0.8340\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.4084 - accuracy: 0.8341\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.4074 - accuracy: 0.8349\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4069 - accuracy: 0.8345\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 0.4063 - accuracy: 0.8347\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.4059 - accuracy: 0.8340 0s - loss: 0.4030 - ac\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.4060 - accuracy: 0.8347\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 0.4050 - accuracy: 0.8350\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4015 - accuracy: 0.8371 ETA: 0s - loss: 0.4034  - 1s 93us/step - loss: 0.4046 - accuracy: 0.8349\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.4045 - accuracy: 0.8347\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4045 - accuracy: 0.8342\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4038 - accuracy: 0.8339\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.4034 - accuracy: 0.8341\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.4035 - accuracy: 0.8339\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4035 - accuracy: 0.8341\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4033 - accuracy: 0.8345\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4031 - accuracy: 0.8351 0s - loss: 0.4048 - accura - ETA: 0s - loss: 0.3999 - ac\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4029 - accuracy: 0.8342 0s - loss: 0.3937 \n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.83 - 1s 88us/step - loss: 0.4027 - accuracy: 0.8331\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 0.4024 - accuracy: 0.8341\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.4027 - accuracy: 0.8341 0s - loss: 0.4033 - accuracy: 0.83\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.83 - 1s 74us/step - loss: 0.4021 - accuracy: 0.8346\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.4027 - accuracy: 0.8342 0s - loss: 0.4011 - accuracy: 0.\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4018 - accuracy: 0.8335\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4025 - accuracy: 0.8351\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.83 - 1s 81us/step - loss: 0.4023 - accuracy: 0.8339\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.4018 - accuracy: 0.8353 0s - loss: 0.4205 - accuracy - ETA: 0s - loss: 0.3968 - ac\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4018 - accuracy: 0.8361\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.4018 - accuracy: 0.8341\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4016 - accuracy: 0.8342\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4018 - accuracy: 0.8342\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4013 - accuracy: 0.8353\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.4014 - accuracy: 0.8344 0s - loss: 0.3975 - accu\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4014 - accuracy: 0.8339 0s - loss: 0.4018 - accuracy: \n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.4014 - accuracy: 0.8361\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.4015 - accuracy: 0.8367\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4017 - accuracy: 0.8339\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4022 - accuracy: 0.83 - 1s 75us/step - loss: 0.4010 - accuracy: 0.8342\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.4016 - accuracy: 0.8324\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4009 - accuracy: 0.8342 0s - loss: 0.3965 \n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.4012 - accuracy: 0.8361\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4013 - accuracy: 0.8346\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4012 - accuracy: 0.8344 0s - loss: 0.3989 - accuracy: 0.\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4010 - accuracy: 0.8341\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4013 - accuracy: 0.8353 0s - loss: 0.3984 \n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4009 - accuracy: 0.8367 0s - loss: 0.4115 - accuracy - ETA: 0s - loss: 0.4034 - accuracy: \n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4012 - accuracy: 0.8321 0s - loss: 0.4309 \n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4023 - accuracy: 0.83 - 1s 74us/step - loss: 0.4008 - accuracy: 0.8326\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4009 - accuracy: 0.8344\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4010 - accuracy: 0.8357\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4011 - accuracy: 0.8326 ETA: 0s - loss: 0.3982 - accu - 1s 74us/step - loss: 0.4004 - accuracy: 0.8336\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4006 - accuracy: 0.8332\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4007 - accuracy: 0.8345\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4004 - accuracy: 0.8363\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4011 - accuracy: 0.8349\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4006 - accuracy: 0.8342\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.4004 - accuracy: 0.8351 0s - loss: 0.4016 - accuracy: \n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4005 - accuracy: 0.8364 0s - loss: 0.4\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.4007 - accuracy: 0.8350\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3999 - accuracy: 0.8347 0s - loss: 0.4064 - accu\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.4007 - accuracy: 0.8347\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4001 - accuracy: 0.8363\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.3999 - accuracy: 0.8340\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4006 - accuracy: 0.8350\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4000 - accuracy: 0.8345\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4003 - accuracy: 0.8341 0s - loss: 0.3914 - accuracy: 0.83 - ETA: 0s - loss: 0.389\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.4004 - accuracy: 0.8339 0s - loss: 0.394\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3998 - accuracy: 0.8341\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4001 - accuracy: 0.8354\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4022 - accuracy: 0.83 - 1s 74us/step - loss: 0.4001 - accuracy: 0.8344\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4006 - accuracy: 0.8346\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4003 - accuracy: 0.8347\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3999 - accuracy: 0.8340 0s - loss: 0.4003 - accuracy: 0.\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4002 - accuracy: 0.8347\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4006 - accuracy: 0.8351 0s - loss: 0.4006 - accuracy\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4001 - accuracy: 0.8336\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3997 - accuracy: 0.8341 0s - loss: 0.3854 \n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4002 - accuracy: 0.8360\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3999 - accuracy: 0.8329\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4006 - accuracy: 0.8339\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4000 - accuracy: 0.8347\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4003 - accuracy: 0.8330\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4000 - accuracy: 0.8341\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4003 - accuracy: 0.8344 0s - loss: 0.400\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4001 - accuracy: 0.8342\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3988 - accuracy: 0.83 - 1s 73us/step - loss: 0.4002 - accuracy: 0.8351\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4000 - accuracy: 0.8335\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.4005 - accuracy: 0.8349\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3997 - accuracy: 0.8351\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4001 - accuracy: 0.8357 0s - loss: 0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2d106b694a8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the ANN to the training dataset\n",
    "ann_classifier.fit(x= x_train, y= y_train, batch_size= 10, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23745051],\n",
       "       [0.4061626 ],\n",
       "       [0.20519778],\n",
       "       [0.07569614],\n",
       "       [0.20627171]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting the test set result\n",
    "y_pred= ann_classifier.predict(x_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred= (y_pred>0.5)#considering threshold = 0.5\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1521,   74],\n",
       "       [ 239,  166]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion metrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "ann_cm= confusion_matrix(y_test, y_pred)\n",
    "ann_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91      1595\n",
      "           1       0.69      0.41      0.51       405\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.78      0.68      0.71      2000\n",
      "weighted avg       0.83      0.84      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844\n"
     ]
    }
   ],
   "source": [
    "ann_accuracy= sklearn.metrics.accuracy_score(y_test, y_pred).round(3)\n",
    "print(ann_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shive\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_classifier= LogisticRegression(random_state=0)\n",
    "lr_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting\n",
    "lr_y_pred= lr_classifier.predict(x_test)\n",
    "lr_y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      1595\n",
      "           1       0.58      0.24      0.34       405\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.71      0.60      0.61      2000\n",
      "weighted avg       0.78      0.81      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811\n"
     ]
    }
   ],
   "source": [
    "lr_accuracy= sklearn.metrics.accuracy_score(y_test, lr_y_pred).round(3)\n",
    "print(lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "models = ['Logistic Regression', 'Artificial Neural Network']\n",
    "accuracies = [0.811,0.859]\n",
    "plt.bar(models, accuracies, width= 0.5)\n",
    "plt.title(\"Accuracy Comparison\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Prediction for customer with following attributes\n",
    "Geography: France\n",
    "Credit Score: 600\n",
    "Gender: Male\n",
    "Age: 40 years old\n",
    "Tenure: 3 years\n",
    "Balance: $60000\n",
    "Number of Products: 2\n",
    "Does this customer have a credit card ? Yes\n",
    "Is this customer an Active Member: Yes\n",
    "Estimated Salary: $50000\"\"\"\n",
    "new_prediction = ann_classifier.predict(sc.transform(np.array([[0.0, 0, 0, 600, 40, 3, 60000, 2, 1, 1, 50000]])))\n",
    "new_prediction= (new_prediction > 0.5)\n",
    "print(new_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating, Improving and Tuning the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def build_ann_classifier():\n",
    "    ann_classifier= Sequential()\n",
    "    ann_classifier.add(Dense(6, activation= \"relu\", kernel_initializer= \"uniform\", input_shape= (11,)))\n",
    "    ann_classifier.add(Dense(6, activation= \"relu\", kernel_initializer= \"uniform\"))\n",
    "    ann_classifier.add(Dense(1, activation= \"sigmoid\", kernel_initializer= \"uniform\"))\n",
    "    ann_classifier.compile(optimizer=\"adam\", loss= \"binary_crossentropy\", metrics= [\"accuracy\"])\n",
    "    return ann_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_classifier= KerasClassifier(build_fn= build_ann_classifier, batch_size= 10, nb_epoch= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies= cross_val_score(estimator= ann_classifier, X= x_train, y= y_train, cv=10, n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.796\n",
      "Variance: 0.01\n"
     ]
    }
   ],
   "source": [
    "mean= round(accuracies.mean(),3)\n",
    "variance= round(accuracies.std(),3)\n",
    "print(\"Mean Accuracy:\", mean)\n",
    "print(\"Variance:\", variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 230us/step - loss: 0.6190 - accuracy: 0.7965\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 233us/step - loss: 0.4888 - accuracy: 0.7968\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 232us/step - loss: 0.5001 - accuracy: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 262us/step - loss: 0.4813 - accuracy: 0.7968\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 247us/step - loss: 0.6199 - accuracy: 0.7932\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 252us/step - loss: 0.5016 - accuracy: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 240us/step - loss: 0.4927 - accuracy: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 224us/step - loss: 0.5153 - accuracy: 0.7989\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 235us/step - loss: 0.4894 - accuracy: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 249us/step - loss: 0.5005 - accuracy: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 367us/step - loss: 0.5100 - accuracy: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 217us/step - loss: 0.5134 - accuracy: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.5004 - accuracy: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 209us/step - loss: 0.5226 - accuracy: 0.7968\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 211us/step - loss: 0.5005 - accuracy: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 235us/step - loss: 0.5101 - accuracy: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 202us/step - loss: 0.5087 - accuracy: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 223us/step - loss: 0.4989 - accuracy: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 229us/step - loss: 0.5044 - accuracy: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 221us/step - loss: 0.5113 - accuracy: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 233us/step - loss: 0.4848 - accuracy: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 267us/step - loss: 0.4838 - accuracy: 0.7972\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 368us/step - loss: 0.4874 - accuracy: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 338us/step - loss: 0.4902 - accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 264us/step - loss: 0.4943 - accuracy: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 224us/step - loss: 0.4857 - accuracy: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 248us/step - loss: 0.5050 - accuracy: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 243us/step - loss: 0.5014 - accuracy: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 230us/step - loss: 0.4985 - accuracy: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 239us/step - loss: 0.4981 - accuracy: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 223us/step - loss: 0.5040 - accuracy: 0.7972\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 235us/step - loss: 0.5035 - accuracy: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 221us/step - loss: 0.5048 - accuracy: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 211us/step - loss: 0.4966 - accuracy: 0.7975\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.5129 - accuracy: 0.7929\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 211us/step - loss: 0.5075 - accuracy: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 216us/step - loss: 0.4918 - accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 210us/step - loss: 0.5030 - accuracy: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 233us/step - loss: 0.4934 - accuracy: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 210us/step - loss: 0.5202 - accuracy: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 235us/step - loss: 0.4915 - accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 219us/step - loss: 0.4894 - accuracy: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 213us/step - loss: 0.5001 - accuracy: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 230us/step - loss: 0.4917 - accuracy: 0.7971\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 246us/step - loss: 0.4955 - accuracy: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 239us/step - loss: 0.4996 - accuracy: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 221us/step - loss: 0.4877 - accuracy: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 221us/step - loss: 0.4870 - accuracy: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 214us/step - loss: 0.6206 - accuracy: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 254us/step - loss: 0.4902 - accuracy: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 220us/step - loss: 0.4937 - accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 194us/step - loss: 0.5140 - accuracy: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 207us/step - loss: 0.4986 - accuracy: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 217us/step - loss: 0.5390 - accuracy: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 220us/step - loss: 0.5261 - accuracy: 0.7926\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 241us/step - loss: 0.4952 - accuracy: 0.7942\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 213us/step - loss: 0.5243 - accuracy: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 197us/step - loss: 0.5201 - accuracy: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 203us/step - loss: 0.5053 - accuracy: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 200us/step - loss: 0.5066 - accuracy: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 122us/step - loss: 0.5601 - accuracy: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 120us/step - loss: 0.5604 - accuracy: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 123us/step - loss: 0.5493 - accuracy: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 112us/step - loss: 0.5551 - accuracy: 0.7972\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 121us/step - loss: 0.5651 - accuracy: 0.7925\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 118us/step - loss: 0.5792 - accuracy: 0.7926\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 121us/step - loss: 0.5557 - accuracy: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 116us/step - loss: 0.5536 - accuracy: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.5803 - accuracy: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.5465 - accuracy: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 105us/step - loss: 0.5898 - accuracy: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.5744 - accuracy: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.5737 - accuracy: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.5865 - accuracy: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.5908 - accuracy: 0.7924\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.6246 - accuracy: 0.7926\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.5731 - accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.5824 - accuracy: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.5653 - accuracy: 0.7956\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.5728 - accuracy: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 120us/step - loss: 0.5479 - accuracy: 0.7971\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 109us/step - loss: 0.5653 - accuracy: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 109us/step - loss: 0.5549 - accuracy: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.5526 - accuracy: 0.7972\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 105us/step - loss: 0.5818 - accuracy: 0.7926\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.5485 - accuracy: 0.7943\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.5603 - accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 155us/step - loss: 0.5654 - accuracy: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 134us/step - loss: 0.5556 - accuracy: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.5474 - accuracy: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 116us/step - loss: 0.5850 - accuracy: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.5615 - accuracy: 0.7968\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 108us/step - loss: 0.5793 - accuracy: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.5858 - accuracy: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.5871 - accuracy: 0.7928\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.5848 - accuracy: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.5758 - accuracy: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 117us/step - loss: 0.6010 - accuracy: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.5662 - accuracy: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 118us/step - loss: 0.6188 - accuracy: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 113us/step - loss: 0.5561 - accuracy: 0.7965\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 116us/step - loss: 0.6082 - accuracy: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.5557 - accuracy: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 108us/step - loss: 0.5383 - accuracy: 0.7975\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 113us/step - loss: 0.5608 - accuracy: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 128us/step - loss: 0.5498 - accuracy: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 178us/step - loss: 0.5644 - accuracy: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 121us/step - loss: 0.5448 - accuracy: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 126us/step - loss: 0.5619 - accuracy: 0.7935\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 113us/step - loss: 0.5588 - accuracy: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 112us/step - loss: 0.5690 - accuracy: 0.7968\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 105us/step - loss: 0.5697 - accuracy: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 126us/step - loss: 0.5643 - accuracy: 0.7942\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 105us/step - loss: 0.5843 - accuracy: 0.7962\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 108us/step - loss: 0.5885 - accuracy: 0.7929\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.6204 - accuracy: 0.7928\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.6038 - accuracy: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.5796 - accuracy: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.5698 - accuracy: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.5910 - accuracy: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.5790 - accuracy: 0.7967\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.6645 - accuracy: 0.7935\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.5861 - accuracy: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 148us/step - loss: 0.5841 - accuracy: 0.7968\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 163us/step - loss: 0.5944 - accuracy: 0.7925\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.5831 - accuracy: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 151us/step - loss: 0.6003 - accuracy: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.6066 - accuracy: 0.7935\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.6183 - accuracy: 0.7932\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.6308 - accuracy: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 110us/step - loss: 0.6172 - accuracy: 0.7942\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 147us/step - loss: 0.6088 - accuracy: 0.7964\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.5885 - accuracy: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.6301 - accuracy: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 142us/step - loss: 0.5981 - accuracy: 0.7937\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.6211 - accuracy: 0.7935\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 145us/step - loss: 0.6104 - accuracy: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.6456 - accuracy: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.6289 - accuracy: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.6457 - accuracy: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.6038 - accuracy: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.5779 - accuracy: 0.7943\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.6063 - accuracy: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.5929 - accuracy: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 108us/step - loss: 0.6046 - accuracy: 0.7904\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.5887 - accuracy: 0.7928\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.5813 - accuracy: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.6335 - accuracy: 0.7942\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.5754 - accuracy: 0.7953\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 121us/step - loss: 0.6272 - accuracy: 0.7931\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.6424 - accuracy: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 109us/step - loss: 0.6131 - accuracy: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.5999 - accuracy: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.6144 - accuracy: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.6275 - accuracy: 0.7911\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.5888 - accuracy: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 112us/step - loss: 0.6137 - accuracy: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.5986 - accuracy: 0.7949\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 113us/step - loss: 0.6196 - accuracy: 0.7936\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.5905 - accuracy: 0.7956\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.6152 - accuracy: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.5793 - accuracy: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.6090 - accuracy: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.5952 - accuracy: 0.7975\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 192us/step - loss: 0.5905 - accuracy: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.5912 - accuracy: 0.7919\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 170us/step - loss: 0.5971 - accuracy: 0.7957\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 189us/step - loss: 0.5710 - accuracy: 0.7961\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 192us/step - loss: 0.5810 - accuracy: 0.7950\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 161us/step - loss: 0.5834 - accuracy: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.6233 - accuracy: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 131us/step - loss: 0.6106 - accuracy: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 134us/step - loss: 0.5810 - accuracy: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 187us/step - loss: 0.6095 - accuracy: 0.7968\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 170us/step - loss: 0.6318 - accuracy: 0.7921\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 176us/step - loss: 0.5987 - accuracy: 0.7942\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.5950 - accuracy: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.5911 - accuracy: 0.7960\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 108us/step - loss: 0.6277 - accuracy: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 183us/step - loss: 0.6050 - accuracy: 0.7958\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 372us/step - loss: 0.4838 - accuracy: 0.7960\n"
     ]
    }
   ],
   "source": [
    "#tuning the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def build_ann_classifier(optimizer):\n",
    "    ann_classifier= Sequential()\n",
    "    ann_classifier.add(Dense(6, activation= \"relu\", kernel_initializer= \"uniform\", input_shape= (11,)))\n",
    "    ann_classifier.add(Dense(6, activation= \"relu\", kernel_initializer= \"uniform\"))\n",
    "    ann_classifier.add(Dense(1, activation= \"sigmoid\", kernel_initializer= \"uniform\"))\n",
    "    ann_classifier.compile(optimizer=optimizer, loss= \"binary_crossentropy\", metrics= [\"accuracy\"])\n",
    "    return ann_classifier\n",
    "\n",
    "ann_classifier= KerasClassifier(build_fn= build_ann_classifier)\n",
    "parameters= {\"batch_size\": [10, 25, 32],\n",
    "            \"nb_epoch\": [50, 100, 500],\n",
    "            \"optimizer\": [\"adam\", \"rmsprop\"]}\n",
    "grid_search= GridSearchCV(estimator= ann_classifier, \n",
    "                          param_grid= parameters, \n",
    "                          cv= 10,  \n",
    "                          scoring= 'accuracy')\n",
    "grid_search= grid_search.fit(x_train, y_train)\n",
    "best_parameter= grid_search.best_params_\n",
    "best_accuracy= grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.797875"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 10, 'nb_epoch': 100, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
