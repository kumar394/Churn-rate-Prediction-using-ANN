{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working directory\n",
    "os.chdir(\"C:\\\\Users\\\\shive\\\\Desktop\\\\MS-BAIM\\\\Courses\\\\online courses\\\\A-Z Deep Learning\\\\Deep_Learning_A_Z\\\\Volume 1 - Supervised Deep Learning\\\\Part 1 - Artificial Neural Networks (ANN)\\\\Section 4 - Building an ANN\\\\Artificial_Neural_Networks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset= pd.read_csv(\"Churn_Modelling.csv\")\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variables\n",
    "geography= pd.get_dummies(dataset[\"Geography\"], drop_first= True)\n",
    "#geography.head(5)\n",
    "gender= pd.get_dummies(dataset[\"Gender\"], drop_first= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Male  Germany  Spain  CreditScore  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0     0        0      0          619   42       2       0.00              1   \n",
       "1     0        0      1          608   41       1   83807.86              1   \n",
       "2     0        0      0          502   42       8  159660.80              3   \n",
       "3     0        0      0          699   39       1       0.00              2   \n",
       "4     0        0      1          850   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping irrelevant columns and concatinating created dummy variables\n",
    "dataset= dataset.drop([\"Geography\", \"Gender\", \"RowNumber\", \"CustomerId\", \"Surname\"], axis=1)\n",
    "dataset= pd.concat([geography, dataset], axis=1)\n",
    "dataset= pd.concat([gender, dataset], axis=1)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering parameters which might affect churn rate based on business intuition\n",
    "x= dataset.iloc[:, :11].values\n",
    "y= dataset.iloc[:, 11].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.1900000e+02,\n",
       "        4.2000000e+01, 2.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 1.0134888e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.0800000e+02,\n",
       "        4.1000000e+01, 1.0000000e+00, 8.3807860e+04, 1.0000000e+00,\n",
       "        0.0000000e+00, 1.0000000e+00, 1.1254258e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 5.0200000e+02,\n",
       "        4.2000000e+01, 8.0000000e+00, 1.5966080e+05, 3.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 1.1393157e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.9900000e+02,\n",
       "        3.9000000e+01, 1.0000000e+00, 0.0000000e+00, 2.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 9.3826630e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.5000000e+02,\n",
       "        4.3000000e+01, 2.0000000e+00, 1.2551082e+05, 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 7.9084100e+04]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into training ans test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split (x,y, test_size=0.2, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.6700000e+02,\n",
       "        3.4000000e+01, 5.0000000e+00, 0.0000000e+00, 2.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 1.6383064e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 4.2700000e+02,\n",
       "        4.2000000e+01, 1.0000000e+00, 7.5681520e+04, 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 5.7098000e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 5.3500000e+02,\n",
       "        2.9000000e+01, 2.0000000e+00, 1.1236734e+05, 1.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 1.8563076e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.5400000e+02,\n",
       "        4.0000000e+01, 5.0000000e+00, 1.0568363e+05, 1.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 1.7361709e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.5000000e+02,\n",
       "        5.7000000e+01, 8.0000000e+00, 1.2677630e+05, 2.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 1.3229849e+05]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "x_train= sc.fit_transform(x_train)\n",
    "x_test= sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.09168714, -0.5698444 ,  1.74309049,  0.16958176, -0.46460796,\n",
       "          0.00666099, -1.21571749,  0.8095029 ,  0.64259497, -1.03227043,\n",
       "          1.10643166],\n",
       "        [ 0.91601335,  1.75486502, -0.57369368, -2.30455945,  0.30102557,\n",
       "         -1.37744033, -0.00631193, -0.92159124,  0.64259497,  0.9687384 ,\n",
       "         -0.74866447],\n",
       "        [-1.09168714, -0.5698444 , -0.57369368, -1.19119591, -0.94312892,\n",
       "         -1.031415  ,  0.57993469, -0.92159124,  0.64259497, -1.03227043,\n",
       "          1.48533467],\n",
       "        [ 0.91601335, -0.5698444 ,  1.74309049,  0.03556578,  0.10961719,\n",
       "          0.00666099,  0.47312769, -0.92159124,  0.64259497, -1.03227043,\n",
       "          1.27652776],\n",
       "        [-1.09168714, -0.5698444 ,  1.74309049,  2.05611444,  1.73658844,\n",
       "          1.04473698,  0.8101927 ,  0.8095029 ,  0.64259497,  0.9687384 ,\n",
       "          0.55837842]]),\n",
       " array([[-1.09168714,  1.75486502, -0.57369368, -0.55204276, -0.36890377,\n",
       "          1.04473698,  0.8793029 , -0.92159124,  0.64259497,  0.9687384 ,\n",
       "          1.61085707],\n",
       "        [-1.09168714, -0.5698444 , -0.57369368, -1.31490297,  0.10961719,\n",
       "         -1.031415  ,  0.42972196, -0.92159124,  0.64259497, -1.03227043,\n",
       "          0.49587037],\n",
       "        [-1.09168714, -0.5698444 ,  1.74309049,  0.57162971,  0.30102557,\n",
       "          1.04473698,  0.30858264, -0.92159124,  0.64259497,  0.9687384 ,\n",
       "         -0.42478674],\n",
       "        [ 0.91601335, -0.5698444 , -0.57369368,  1.41696129, -0.65601634,\n",
       "         -0.33936434,  0.57533623, -0.92159124, -1.55619021, -1.03227043,\n",
       "         -0.18777657],\n",
       "        [ 0.91601335,  1.75486502, -0.57369368,  0.57162971, -0.08179119,\n",
       "          0.00666099,  1.38961097,  0.8095029 ,  0.64259497,  0.9687384 ,\n",
       "          0.61684179]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5], x_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the ANN\n",
    "ann_classifier= Sequential()\n",
    "#adding input layers and hidden layers\n",
    "ann_classifier.add(Dense(6, activation= \"relu\", kernel_initializer= \"uniform\", input_shape= (11,)))\n",
    "#adding second hidden layers\n",
    "ann_classifier.add(Dense(6, activation= \"relu\", kernel_initializer= \"uniform\"))\n",
    "#adding the output layer\n",
    "ann_classifier.add(Dense(1, activation= \"sigmoid\", kernel_initializer= \"uniform\"))\n",
    "#compiling the ANN\n",
    "ann_classifier.compile(optimizer=\"adam\", loss= \"binary_crossentropy\", metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.4824 - accuracy: 0.7959\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 2s 192us/step - loss: 0.4177 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 2s 189us/step - loss: 0.4077 - accuracy: 0.7999\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 177us/step - loss: 0.3971 - accuracy: 0.8284\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 185us/step - loss: 0.3887 - accuracy: 0.8285\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.3817 - accuracy: 0.8310\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 164us/step - loss: 0.3759 - accuracy: 0.8435\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 173us/step - loss: 0.3718 - accuracy: 0.8451\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 2s 190us/step - loss: 0.3683 - accuracy: 0.8474\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 182us/step - loss: 0.3658 - accuracy: 0.8486\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.3626 - accuracy: 0.8516\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 2s 239us/step - loss: 0.3617 - accuracy: 0.8519\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.3601 - accuracy: 0.8512\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 2s 256us/step - loss: 0.3588 - accuracy: 0.8539\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 2s 260us/step - loss: 0.3582 - accuracy: 0.8541\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 2s 251us/step - loss: 0.3563 - accuracy: 0.8559\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.3570 - accuracy: 0.8564\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.3557 - accuracy: 0.8565\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.3547 - accuracy: 0.8554\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 2s 243us/step - loss: 0.3538 - accuracy: 0.8560\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 2s 252us/step - loss: 0.3536 - accuracy: 0.8572\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 183us/step - loss: 0.3529 - accuracy: 0.8556\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 2s 198us/step - loss: 0.3524 - accuracy: 0.8572\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 171us/step - loss: 0.3511 - accuracy: 0.8553\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 180us/step - loss: 0.3510 - accuracy: 0.8584\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 2s 203us/step - loss: 0.3507 - accuracy: 0.8587\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 2s 237us/step - loss: 0.3499 - accuracy: 0.8585\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.3487 - accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 2s 193us/step - loss: 0.3492 - accuracy: 0.8579\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.3491 - accuracy: 0.8579\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 2s 261us/step - loss: 0.3495 - accuracy: 0.8572\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 2s 250us/step - loss: 0.3482 - accuracy: 0.8583\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.3472 - accuracy: 0.8585\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.3482 - accuracy: 0.8554\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 2s 241us/step - loss: 0.3477 - accuracy: 0.8581\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.3467 - accuracy: 0.8605\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 2s 211us/step - loss: 0.3472 - accuracy: 0.8570\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.3463 - accuracy: 0.8626\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.3475 - accuracy: 0.8593\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 175us/step - loss: 0.3466 - accuracy: 0.8569\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 180us/step - loss: 0.3464 - accuracy: 0.8594\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 173us/step - loss: 0.3462 - accuracy: 0.8619\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 2s 270us/step - loss: 0.3465 - accuracy: 0.8595\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 2s 237us/step - loss: 0.3460 - accuracy: 0.8618\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 2s 193us/step - loss: 0.3460 - accuracy: 0.8556\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 2s 206us/step - loss: 0.3458 - accuracy: 0.8589\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 2s 195us/step - loss: 0.3460 - accuracy: 0.8608\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.3450 - accuracy: 0.8618\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.3459 - accuracy: 0.8583\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 183us/step - loss: 0.3457 - accuracy: 0.8606\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 2s 199us/step - loss: 0.3447 - accuracy: 0.8609\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 2s 236us/step - loss: 0.3447 - accuracy: 0.8581\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 2s 206us/step - loss: 0.3439 - accuracy: 0.8604\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 2s 224us/step - loss: 0.3451 - accuracy: 0.8574\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.3444 - accuracy: 0.8566\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 2s 198us/step - loss: 0.3446 - accuracy: 0.8611\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 179us/step - loss: 0.3436 - accuracy: 0.8601\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 180us/step - loss: 0.3447 - accuracy: 0.8591\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 2s 208us/step - loss: 0.3447 - accuracy: 0.8599\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 183us/step - loss: 0.3446 - accuracy: 0.8585\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 2s 195us/step - loss: 0.3438 - accuracy: 0.8620\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.3442 - accuracy: 0.8572\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 2s 190us/step - loss: 0.3431 - accuracy: 0.8615\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 2s 204us/step - loss: 0.3437 - accuracy: 0.8599\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 2s 205us/step - loss: 0.3442 - accuracy: 0.8561\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.3436 - accuracy: 0.8611\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 2s 244us/step - loss: 0.3439 - accuracy: 0.8601\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 2s 248us/step - loss: 0.3427 - accuracy: 0.8595\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.3428 - accuracy: 0.8597\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 0.3426 - accuracy: 0.8618\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.3435 - accuracy: 0.8599\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 2s 191us/step - loss: 0.3433 - accuracy: 0.8591\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 2s 268us/step - loss: 0.3425 - accuracy: 0.8599\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 2s 253us/step - loss: 0.3432 - accuracy: 0.8581\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 2s 277us/step - loss: 0.3426 - accuracy: 0.8585\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 2s 205us/step - loss: 0.3422 - accuracy: 0.8601\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.3432 - accuracy: 0.8574\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 2s 213us/step - loss: 0.3414 - accuracy: 0.8602\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 186us/step - loss: 0.3427 - accuracy: 0.8596\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 2s 257us/step - loss: 0.3420 - accuracy: 0.8608\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 2s 261us/step - loss: 0.3425 - accuracy: 0.8591\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 176us/step - loss: 0.3421 - accuracy: 0.8597\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 178us/step - loss: 0.3412 - accuracy: 0.8580\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 179us/step - loss: 0.3419 - accuracy: 0.8602\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 172us/step - loss: 0.3418 - accuracy: 0.8580\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 187us/step - loss: 0.3419 - accuracy: 0.8608\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 2s 199us/step - loss: 0.3414 - accuracy: 0.8602\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 180us/step - loss: 0.3413 - accuracy: 0.8614\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 185us/step - loss: 0.3421 - accuracy: 0.8599\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 2s 206us/step - loss: 0.3414 - accuracy: 0.8639\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 2s 244us/step - loss: 0.3422 - accuracy: 0.8594\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 2s 201us/step - loss: 0.3415 - accuracy: 0.8615\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 2s 199us/step - loss: 0.3411 - accuracy: 0.8644\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 177us/step - loss: 0.3419 - accuracy: 0.8587\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 177us/step - loss: 0.3414 - accuracy: 0.8611\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 183us/step - loss: 0.3414 - accuracy: 0.8618\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 2s 202us/step - loss: 0.3416 - accuracy: 0.8611\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 177us/step - loss: 0.3410 - accuracy: 0.8610\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.3414 - accuracy: 0.8605\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 2s 239us/step - loss: 0.3414 - accuracy: 0.8595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x217a98a1fd0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the ANN to the training dataset\n",
    "ann_classifier.fit(x= x_train, y= y_train, batch_size= 10, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37101465],\n",
       "       [0.38029036],\n",
       "       [0.15223905],\n",
       "       [0.07192841],\n",
       "       [0.06970111]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting the test set result\n",
    "y_pred= ann_classifier.predict(x_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred= (y_pred>0.5)#considering threshold = 0.5\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1504,   91],\n",
       "       [ 191,  214]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion metrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "ann_cm= confusion_matrix(y_test, y_pred)\n",
    "ann_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      1595\n",
      "           1       0.70      0.53      0.60       405\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.79      0.74      0.76      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859\n"
     ]
    }
   ],
   "source": [
    "ann_accuracy= sklearn.metrics.accuracy_score(y_test, y_pred).round(3)\n",
    "print(ann_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shive\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_classifier= LogisticRegression(random_state=0)\n",
    "lr_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting\n",
    "lr_y_pred= lr_classifier.predict(x_test)\n",
    "lr_y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      1595\n",
      "           1       0.58      0.24      0.34       405\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.71      0.60      0.61      2000\n",
      "weighted avg       0.78      0.81      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811\n"
     ]
    }
   ],
   "source": [
    "lr_accuracy= sklearn.metrics.accuracy_score(y_test, lr_y_pred).round(3)\n",
    "print(lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "models = ['Logistic Regression', 'Artificial Neural Network']\n",
    "accuracies = [0.811,0.859]\n",
    "plt.bar(models, accuracies, width= 0.5)\n",
    "plt.title(\"Accuracy Comparison\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
